# Chatbot RAG con Memoria DinÃ¡mica (OpenAI + Gradio)

Este proyecto implementa un **chatbot** basado en **RAG (Retrieval-Augmented Generation)** que combina recuperaciÃ³n de informaciÃ³n de documentos con memoria dinÃ¡mica. El chatbot puede responder preguntas usando los documentos cargados y mantener un **historial resumido** de la conversaciÃ³n para mejorar la coherencia y la eficiencia. AdemÃ¡s tiene la capacidad de responder a consultas fuera de su base de conocimiento. 

---

## ğŸ›  TecnologÃ­as utilizadas

* **Python 3.10+**
* **LangChain**: gestiÃ³n de memoria y RAG
* **FAISS**: motor de bÃºsqueda vectorial
* **OpenAI**: embeddings (`text-embedding-3-small`) y LLM (`gpt-4o-mini`)
* **Gradio**: interfaz web interactiva
* **PyPDF2**: carga de documentos PDF

---

## ğŸ“‚ Estructura del proyecto

```
chatbot-rag/
â”‚
â”œâ”€ data/
â”‚   â””â”€ raw/                # Documentos para RAG (.pdf)
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ gradio_app.py        # Interfaz principal
â”‚   â”œâ”€ rag/
â”‚   â”‚   â”œâ”€ loader.py        # Carga de documentos
â”‚   â”‚   â”œâ”€ embedder.py      # GeneraciÃ³n de embeddings
â”‚   â”‚   â”œâ”€ vectorstore.py   # FAISS VectorStore
â”‚   â”‚   â”œâ”€ retriever.py     # Recuperador de contexto
â”‚   â”‚   â””â”€ llm_handler.py   # Interfaz LLM OpenAI
â”‚   â””â”€ memory/
â”‚       â””â”€ memory_manager.py # GestiÃ³n de memoria dinÃ¡mica y resÃºmenes
â”‚
â”œâ”€ requirements.txt         # Dependencias del proyecto
â””â”€ README.md
```

---

## âš¡ CaracterÃ­sticas

1. **RAG (Retrieval-Augmented Generation)**:
   Recupera informaciÃ³n relevante de documentos cargados y la combina con la memoria del usuario para generar respuestas mÃ¡s precisas. Tal y como estÃ¡ implementado el RAG, es posible preguntar sobre imÃ¡genes y figuras de los documentos, asÃ­ como sobre ciertos datos estructurados que aparezcan en ellos. 

2. **Memoria dinÃ¡mica con resumen automÃ¡tico**:
   Cuando la memoria supera un lÃ­mite de tokens, se genera automÃ¡ticamente un **resumen**, que luego se integra en la memoria para mantener la coherencia de la conversaciÃ³n.

3. **Soporte documentos PDF**:
   Compatible con `.pdf`.

4. **Interfaz web con Gradio**:
   Chat interactivo fÃ¡cil de usar que limpia automÃ¡ticamente la entrada del usuario.

5. **Embeddings y LLM con OpenAI**:

   * Embeddings: `text-embedding-3-small`
   * LLM: `gpt-4o-mini` (personalizable con la API key de OpenAI)

---

## ğŸš€ InstalaciÃ³n

1. Clonar el repositorio:

```bash
git clone https://github.com/9jose9/prueba-turing.git
```

2. Crear un entorno virtual:

```bash
python -m venv venv
```

3. Activar el entorno:

* Windows:

```bash
venv\Scripts\activate
```

* Linux / macOS:

```bash
source venv/bin/activate
```

4. Instalar dependencias:

```bash
pip install -r requirements.txt
```

5. Configurar API key de OpenAI:

```bash
export OPENAI_API_KEY="tu_api_key"
```

> En Windows PowerShell:

```powershell
setx OPENAI_API_KEY "tu_api_key"
```

---

## ğŸ“ Uso

1. Coloca tus documentos PDF en `data/raw/`.
2. Ejecuta la aplicaciÃ³n Gradio:

```bash
cd src
python gradio_app.py
```

3. Abre el navegador en la URL que Gradio indique (normalmente `http://127.0.0.1:7860/`).
4. Escribe tu pregunta en el chat y obtÃ©n respuestas usando RAG + memoria dinÃ¡mica.

---

## âš™ ConfiguraciÃ³n

* `chunk_size` y `chunk_overlap` en `loader.py` para ajustar cÃ³mo se fragmentan los documentos.
* `max_tokens` en `memory_manager.py` para definir cuÃ¡ndo se genera un resumen de memoria.
* `top_k` en `retriever.py` para definir cuÃ¡ntos documentos se recuperan para la generaciÃ³n de la respuesta.

---

## ğŸ“Œ Consideraciones

* Cada resumen de memoria se genera usando la informaciÃ³n acumulada hasta el momento, lo que permite mantener la coherencia incluso en conversaciones largas.

